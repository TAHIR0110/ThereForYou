{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client() # launch local dask.distributed client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a9372847514b48b866bfcfcf0989c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client.cluster\n",
    "#Click on Dashboard to visualise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from datetime import timedelta\n",
    "from dateutil.parser import parser\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import auc, accuracy_score, precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import Pipeline\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(os.path.expanduser(r\"./confusion_matrix.png\"),\n",
    "                format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.close();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cross_validation(cv, X, y, pipeline):\n",
    "    tprs = []; \n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    i = 0\n",
    "    for train, test in cv.split(X, y):\n",
    "\n",
    "        probas_= pipeline.fit(X[train], y[train]).predict_proba(X[test])\n",
    "            # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "        label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "        i += 1\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Luck', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "    label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "    lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "            label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    #plt.tight_layout()\n",
    "    plt.title('ROC with stratified 5-fold cross validation')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(os.path.expanduser(\"./ROC_stratified_kfold.png\"),\n",
    "                format='png',dpi=300); \n",
    "    plt.close();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8, 'gamma': 0, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.8}\n",
      "0.9872513524030729\n",
      "Raw AUC score: 0.9872513524030729\n",
      "colsample_bytree: 0.8\n",
      "gamma: 0\n",
      "max_depth: 5\n",
      "min_child_weight: 1\n",
      "subsample: 0.8\n",
      "{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 5, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8, 'njobs': -1}\n",
      "Confusion matrix, without normalization\n",
      "[[ 50  13]\n",
      " [ 10 291]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhijit/anaconda3/envs/idp/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.95408058166504\n",
      "Classification report for classifier Pipeline(memory='/tmp/tmp4t26thuu',\n",
      "     steps=[('scaler', Normalizer(copy=True, norm='l2')), ('smt', SMOTETomek(k=None, kind_smote=None, m=None, n_jobs=None, out_step=None,\n",
      "      random_state=None, ratio='auto', smote=None, tomek=None)), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1...\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1))]):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.79      0.81        63\n",
      "          1       0.96      0.97      0.96       301\n",
      "\n",
      "avg / total       0.94      0.94      0.94       364\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "##############\n",
    "from dask_ml.model_selection import GridSearchCV as dasksearchCV # GridSearchCV \n",
    "##############\n",
    "from xgboost import XGBClassifier\n",
    "def main():\n",
    "    import time\n",
    "    start = time.time()\n",
    "    with open('./pkl/X.pkl', 'rb') as fh: # Load data set\n",
    "            X = dill.load(fh)\n",
    "    with open('./pkl/y.pkl', 'rb') as fh:\n",
    "            y = dill.load(fh)\n",
    "    scaler = Normalizer()\n",
    "    smote_etomek=SMOTETomek(ratio='auto')\n",
    "    cachedir = mkdtemp()\n",
    "    cv = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "    classifier = XGBClassifier()\n",
    "    \n",
    "    # A parameter grid for XGBoost\n",
    "    params = {\n",
    "            'min_child_weight': [1, 5, 10],\n",
    "            'gamma': [0, 0.5, 1, 1.5, 2, 5],\n",
    "            'subsample': [0.6, 0.8, 1.0],\n",
    "            'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "            'max_depth': [1, 3, 4, 5, 10],\n",
    "            }\n",
    "    pipeline = Pipeline([('scaler',scaler),('smt', smote_etomek),\n",
    "                         ('clf',classifier),],memory=cachedir)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "    sss.get_n_splits(X, y)\n",
    "    for train_index, test_index in sss.split(X, y): \n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index] # make training and test set\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        clf = dasksearchCV(classifier, params, n_jobs=8, \n",
    "               cv=3, \n",
    "               scoring='roc_auc',\n",
    "                refit=True) \n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        print(clf.best_params_)\n",
    "        print(clf.best_score_)\n",
    "        best_parameters, score = clf.best_params_, clf.best_score_\n",
    "        print('Raw AUC score:', score)\n",
    "        for param_name in sorted(best_parameters.keys()):\n",
    "            print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        classifier = XGBClassifier(**best_parameters,njobs=-1)\n",
    "        plot_cross_validation(cv, X_train, y_train, pipeline) # do 5 fold stratified cross-validation\n",
    "        clf = pipeline.fit(X_train, y_train) # \n",
    "        \n",
    "        print(classifier.get_params())\n",
    "        expected = y_test\n",
    "        predicted = clf.predict(X_test) # test performance on test set\n",
    "        plot_confusion_matrix(confusion_matrix(expected, predicted),classes = [\"Non-Zika\",\"Zika\"])\n",
    "    print(time.time()- start)\n",
    "    from sklearn import metrics\n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "              % (clf, metrics.classification_report(expected, predicted)))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
